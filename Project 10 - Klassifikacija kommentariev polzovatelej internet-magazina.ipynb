{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Классификация комментариев пользователей интернет-магазина"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Введение\n",
    "\n",
    "Интернет-магазин запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.  \n",
    "В нашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Задача - обучить модель классифицировать комментарии на позитивные и негативные. Метрика качества - *F1* - должна быть не меньше 0.75. \n",
    "\n",
    "#### Описание данных\n",
    "\n",
    "Данные находятся в файле `toxic_comments.csv`. Столбец *text* в нём содержит текст комментария, а *toxic* — целевой признак.\n",
    "\n",
    "#### План работы\n",
    "\n",
    "1. Загрузка и подготовка данных.\n",
    "2. Обучение разных моделей. \n",
    "3. Выводы.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Загрузка и подготовка данных."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1. Загрузка и обзор данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотек\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# загрузка данных\n",
    "df = pd.read_csv('/datasets/toxic_comments.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      "text     159571 non-null object\n",
      "toxic    159571 non-null int64\n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Произведем лемматизацию, очистим тексты от ненужных символов, переведем тексты в стандартный для Python формат - кодировку Unicode."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2. Подготовка данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт библиотеки NLTK (Natural Language Toolkit), модуля 're' (regular expressions), инициализация лемматизатора\n",
    "import nltk\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция удаления ненужных символов и лемматизации\n",
    "def pre_process(text):\n",
    "    text1 = re.sub(r'[^a-zA-Z]',' ', text) # замена ненужных символов на пробелы\n",
    "    tokens = nltk.word_tokenize(text1) # токенизация - разбивка текста на отдельные слова\n",
    "    text2 = ' '.join([lemmatizer.lemmatize(w) for w in tokens]) # лемматизация токенов и объединение в строку\n",
    "    return text2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 4min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# применим функцию удаления ненужных символов и лемматизации к столбцу 'text'\n",
    "df['text']=df['text'].apply(pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переведем столбец'text' в нижний регистр:\n",
    "df['text'] = df['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# переведем тексты в кодировку Unicode\n",
    "df['text'] = df['text'].astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>explanation why the edits made under my userna...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>d aww he match this background colour i m seem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>hey man i m really not trying to edit war it s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>more i can t make any real suggestion on impro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>you sir are my hero any chance you remember wh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  explanation why the edits made under my userna...      0\n",
       "1  d aww he match this background colour i m seem...      0\n",
       "2  hey man i m really not trying to edit war it s...      0\n",
       "3  more i can t make any real suggestion on impro...      0\n",
       "4  you sir are my hero any chance you remember wh...      0"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1296"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# еще раз проверим на наличие дупликатов: они могли появиться в процессе предобработки\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# удалим дупликаты\n",
    "df = df.drop_duplicates().reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Данные готовы к векторизации и работе с моделями."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3. Анализ количества токсичных комментариев."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравним количество позитивных и негативных (токсичных) комментариев графически и вычислим долю каждого типа комментариев."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# количество негативных отзывов\n",
    "neg = df['toxic'].sum()\n",
    "# количество позитивных отзывов\n",
    "pos = len(df)-neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовка к построению графика \n",
    "picture = pd.DataFrame(data = [pos, neg], columns = ['qty'], index = ['positive', 'negative'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x25f118652c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "picture.plot.bar(grid=True, rot=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Доля позитивных отзывов, %: 89.8\n",
      "Доля негативных отзывов, %: 10.2\n"
     ]
    }
   ],
   "source": [
    "print('Доля позитивных отзывов, %:', round(pos/len(df)*100,1))\n",
    "print('Доля негативных отзывов, %:', round(neg/len(df)*100,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Обучение моделей и тестирование."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Рассмотрим работу моделей \"мешок слов\", \"N-граммы\" и \"TF-IDF\" на основе алгоритма логистической регрессии, дерева решений и случайного леса.   \n",
    "Чтобы сделать код короче, одновременно с расчетом значения метрики на валидационной выборке рассчитаем ее значение и на тестовой выборке."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# импорт функций\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# создадим корпус (список текстов)\n",
    "corpus = df['text'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделение тестовой выборки\n",
    "corpus_1, corpus_test, target_1, target_test = train_test_split(corpus, df['toxic'], test_size=0.2, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# выделение обучающей и валидационной выборок\n",
    "corpus_train, corpus_valid, target_train, target_valid = train_test_split(corpus_1, target_1, test_size=0.25, random_state=12345)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# подготовим пакет 'stopwords' для удаления слов без смысловой нагрузки.\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заготовка таблицы результата\n",
    "columns = ['method', 'model', 'max_depth', 'n_estimators', 'f1_score_valid', 'f1_score_test']\n",
    "data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# функция обучения и работы модели с расчетом значения метрики\n",
    "def score (model, features_train, target_train, features_valid, features_test, target_valid, target_test):\n",
    "    # обучение модели\n",
    "    model.fit(features_train, target_train)\n",
    "    # работа модели на валидационной выборке\n",
    "    pred_valid = model.predict(features_valid)\n",
    "    # работа модели на тестовой выборке\n",
    "    pred_test = model.predict(features_test)\n",
    "    # значение метрики на валидации\n",
    "    f1_score_valid = f1_score(target_valid, pred_valid)\n",
    "    # значение метрики на тесте\n",
    "    f1_score_test = f1_score(target_test, pred_test)\n",
    "    return f1_score_valid, f1_score_test "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " В цикле ниже рассмотрим только модель логистической регрессии. Дерево решений и случайный лес при подборе методов и параметров работают неприемлимо долго (с их участием цикл длится 1 час 50 мин), поэтому будут рассмотрены отдельно с уже подобранными параметрами."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "При работе с логистической регрессией пришлось изменить параметр 'max_iter': при дефолтном значении max_iter = 100 выходило предупреждение ConvergenceWarning и рекомендация увеличить число итераций."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 6min 38s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# \"мешок слов\", биграммы и tf_idf для логистической регрессии\n",
    "\n",
    "for method in ['bag', 'bi_gramm', 'tf_idf']:\n",
    "    # инициализация счетчика в зависимости от метода\n",
    "    if method == 'bag':\n",
    "        count = CountVectorizer(stop_words=stop_words)\n",
    "    if method == 'bi_gramm':\n",
    "        count = CountVectorizer(ngram_range=(2, 2), stop_words=stop_words)\n",
    "    if method == 'tf_idf':\n",
    "        count = TfidfVectorizer(stop_words=stop_words)\n",
    "    # настройка счетчика\n",
    "    count.fit(corpus_train)\n",
    "    # трансформация признаков\n",
    "    features_train = count.transform(corpus_train)\n",
    "    features_valid = count.transform(corpus_valid)\n",
    "    features_test = count.transform(corpus_test)\n",
    "    # инициализация модели\n",
    "    model = LogisticRegression(class_weight='balanced', random_state=12345, solver='lbfgs', max_iter = 800)\n",
    "    # функция обучения и работы модели с расчетом значения метрики\n",
    "    f1_score_valid, f1_score_test = score (model, features_train, target_train, features_valid, features_test, target_valid, target_test)\n",
    "    # внесение результата в таблицу сравнения \n",
    "    data.append([method, 'logistic_regression', np.nan, np.nan, f1_score_valid, f1_score_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ниже приведен пример работы дерева решений по методу 'tf_idf' с параметром max_depth = 15. При этих параметрах дерево решений показало лучшие результаты f1. Фактически были рассмотрены также методы \"мешок слов\" и биграммы при max_depth = (5, 10, 15)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 57.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# 'tf_idf' для дерева решений\n",
    "\n",
    "# инициализация счетчика\n",
    "count = TfidfVectorizer(stop_words=stop_words)\n",
    "# настройка счетчика\n",
    "count.fit(corpus_train)\n",
    "# трансформация признаков\n",
    "features_train = count.transform(corpus_train)\n",
    "features_valid = count.transform(corpus_valid)\n",
    "features_test = count.transform(corpus_test)\n",
    "# инициализация модели\n",
    "model = DecisionTreeClassifier(max_depth = 15, random_state = 12345)\n",
    "# функция обучения и работы модели с расчетом значения метрики\n",
    "f1_score_valid, f1_score_test = score (model, features_train, target_train, features_valid, features_test, target_valid, target_test)\n",
    "# внесение результата в таблицу сравнения\n",
    "data.append(['tf_idf', 'decision_tree', 15, np.nan, f1_score_valid, f1_score_test])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для случайного леса пришлось применить большие (=200...800) значения 'max_depth': при значениях менее 15 появлялось предупреждение, что f1 не может быть расчитано в силу отсутствия предсказанных значений, а при 'max_depth' менее 50 значение f1 оказывалось близко к нулю. При этом значение параметра 'n_estimators' (рассмотрено 5, 15, 30) на результат влияло несущественно. Но модель случайного леса нормально работала при 'max_depth = None' (значение по умолчанию). Это значение и было оставлено в итоговой версии кода.  \n",
    "Для случайного леса оставили только метод \"мешок слов\", т.к. попытка включения в цикл методов биграмм и tf_idf привела к неприемлимо долгой работе кода при результате очень близком к результату \"мешка слов\" (tf_idf) либо гораздо худшем (биграммы)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 1min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# \"мешок слов\" для случайного леса\n",
    "\n",
    "# инициализация счетчика уникальных слов\n",
    "count = CountVectorizer(stop_words=stop_words)\n",
    "# настройка счетчика\n",
    "count.fit(corpus_train)\n",
    "# трансформация признаков\n",
    "features_train = count.transform(corpus_train)\n",
    "features_valid = count.transform(corpus_valid)\n",
    "features_test = count.transform(corpus_test)\n",
    "# инициализация модели\n",
    "model = RandomForestClassifier(n_estimators = 5, random_state = 12345)\n",
    "# функция обучения и работы модели с расчетом значения метрики\n",
    "f1_score_valid, f1_score_test = score (model, features_train, target_train, features_valid, features_test, target_valid, target_test)\n",
    "# внесение результата в таблицу сравнения\n",
    "data.append(['bag', 'random_forest', np.nan, 5, f1_score_valid, f1_score_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>method</th>\n",
       "      <th>model</th>\n",
       "      <th>max_depth</th>\n",
       "      <th>n_estimators</th>\n",
       "      <th>f1_score_valid</th>\n",
       "      <th>f1_score_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>bag</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.756416</td>\n",
       "      <td>0.754557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>tf_idf</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.743808</td>\n",
       "      <td>0.747860</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>bag</td>\n",
       "      <td>random_forest</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.656536</td>\n",
       "      <td>0.678073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>tf_idf</td>\n",
       "      <td>decision_tree</td>\n",
       "      <td>15.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.611288</td>\n",
       "      <td>0.628913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>bi_gramm</td>\n",
       "      <td>logistic_regression</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.496815</td>\n",
       "      <td>0.496858</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     method                model  max_depth  n_estimators  f1_score_valid  \\\n",
       "0       bag  logistic_regression        NaN           NaN        0.756416   \n",
       "1    tf_idf  logistic_regression        NaN           NaN        0.743808   \n",
       "2       bag        random_forest        NaN           5.0        0.656536   \n",
       "3    tf_idf        decision_tree       15.0           NaN        0.611288   \n",
       "4  bi_gramm  logistic_regression        NaN           NaN        0.496815   \n",
       "\n",
       "   f1_score_test  \n",
       "0       0.754557  \n",
       "1       0.747860  \n",
       "2       0.678073  \n",
       "3       0.628913  \n",
       "4       0.496858  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# таблица результата\n",
    "summary = pd.DataFrame(data=data, columns=columns).sort_values(by='f1_score_valid', ascending=False).reset_index(drop=True)\n",
    "summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Выводы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Была проделана следующая работа:  \n",
    "После загрузки данных была произведена леммитизация текстов, ненужные символы были удалены. Для лемматизации была использована библиотека NLTK (Natural Language Toolkit). Тексты были переведены в кодировку Unicode.  \n",
    "Векторизацию текстов произвели тремя способами - методом \"мешок слов\", биграмма и TD-IDF. Для всех трех методов при построении модели предсказания попробовали алгоритмы логистической регрессии, дерева решений и случайного леса.  \n",
    "Лучший результат показал метод \"мешок слов\" для логистической регрессии - значение метрики F1 на тестовой выборке удовлетворяет поставленному условию F1 >= 0.75."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
